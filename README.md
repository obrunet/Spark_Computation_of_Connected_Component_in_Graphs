# Computation of Connected Component in Graphs with Spark  

Implementation of the "CCF: Fast and Scalable Connected Component Computation in MapReduce" paper with Spark. Study of its scalability on several datasets using various clusters' sizes on Databricks and Google Cloud Platform (GCP)

TODO:
- EDA data exploration
- barplot in 3D with export in html
- several datasets
- databricks run time
- time data loading & processing
- use graphx of spark
-  both RDD and DataFrames
- Python implementations must be provided
- comparing the RDD and DataFrame versions conducted on graphs of increasing size
- For small graphs use Databricks, for bigger ones use the cluster
- commande spark-submit

## Table of content
TODO


# Abstract

# Description of the CCF algorithm
a description of the adopted solution 4 points

# Spark Implementation
designed algorithms plus related global comments/description 4 points; comments to main fragments of code 4 points


# Scalability Analysis
experimental analysis, concerning in particular scalability 3 points

# Conclusion
comments about the experimental analysis outlining weak and strong points of the algorithms. 3 points

# Appendix
including all the code code. 2 points
code + interactive graph

# References
- https://www.cse.unr.edu/~hkardes/pdfs/ccf.pdf