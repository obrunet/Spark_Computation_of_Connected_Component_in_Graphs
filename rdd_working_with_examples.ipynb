{"cells":[{"cell_type":"code","execution_count":1,"id":"00733dba","metadata":{},"outputs":[],"source":["import time\n","import pyspark\n","from pyspark.sql import SparkSession\n","\n","\n","BUCKET_INPUT_PATH = \"gs://iasd-input-data\"\n","DATASET_PATHS = {\n","    \"notre_dame\": f\"{BUCKET_INPUT_PATH}/web-NotreDame.txt\",\n","    \"berk_stan.txt\": f\"{BUCKET_INPUT_PATH}/web-BerkStan.txt\",\n","    \"stanford.txt\": f\"{BUCKET_INPUT_PATH}/web-Stanford.txt\",\n","    \"google.txt\": f\"{BUCKET_INPUT_PATH}/web-Google.txt\"\n","}\n","\n","dataset_path = f\"{BUCKET_INPUT_PATH}/test.txt\""]},{"cell_type":"code","execution_count":2,"id":"56521067","metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://dev-m.us-central1-a.c.iasd4-364813.internal:33605\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fb675a96f40>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["spark_session = SparkSession \\\n","    .builder \\\n","    .appName(\"Python Spark SQL basic example\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()\n","\n","spark_context = spark_session.sparkContext\n","\n","spark_session"]},{"cell_type":"code","execution_count":3,"id":"f3f53146","metadata":{},"outputs":[],"source":["def load_rdd(path):\n","    return spark_context.textFile(path)\n","\n","\n","def preprocess_rdd(rdd):\n","    return rdd.filter(lambda x: \"#\" not in x) \\\n","                .map(lambda x: x.split(\"\\t\")) \\\n","                .map(lambda x: (int(x[0]), int(x[1])))"]},{"cell_type":"code","execution_count":null,"id":"cf04849e","metadata":{},"outputs":[],"source":["rdd_raw = load_rdd(dataset_path)\n","rdd_raw.take(5)"]},{"cell_type":"code","execution_count":null,"id":"e5d497e9","metadata":{},"outputs":[],"source":["rdd = preprocess_rdd(rdd_raw)\n","rdd.take(5)"]},{"cell_type":"markdown","id":"80c6389e","metadata":{},"source":["iterate map"]},{"cell_type":"code","execution_count":4,"id":"db04cbd3","metadata":{},"outputs":[],"source":["def iterate_map_rdd(rdd):\n","    return rdd.union(rdd.map(lambda x : (x[1], x[0])))"]},{"cell_type":"code","execution_count":null,"id":"cd56c9e7","metadata":{},"outputs":[],"source":["rdd_iterate_map = iterate_map_rdd(rdd)\n","rdd_iterate_map.take(10)"]},{"cell_type":"code","execution_count":5,"id":"1d24a4e2","metadata":{},"outputs":[],"source":["# good\n","new_pairs = spark_context.accumulator(0)\n","# countnew_pairs function to know if additional CCF iteration is needed\n","def count_new_pairs(x):\n","  global new_pairs\n","  k, values = x\n","  min, value_list = k, []\n","  for v in values:\n","    if v < min:\n","       min = v\n","    value_list.append(v)\n","  if min < k:\n","    yield((k, min))\n","    for v in value_list:\n","      if min != v:\n","        new_pairs += 1\n","        yield((v, min))\n","        \n","\n","def iterate_reduce_rdd(rdd):\n","    return rdd.groupByKey().flatMap(lambda x: count_new_pairs(x)).sortByKey()"]},{"cell_type":"code","execution_count":null,"id":"e7d03c05","metadata":{},"outputs":[],"source":["rdd_iterate_reduce = iterate_reduce_rdd(rdd_iterate_map)\n","rdd_iterate_reduce.take(20)"]},{"cell_type":"code","execution_count":6,"id":"98beaa58","metadata":{},"outputs":[],"source":["def compute_rdd(rdd):\n","    nb_iteration = 0\n","    while True:\n","        nb_iteration += 1\n","        start_pair = new_pairs.value\n","\n","        rdd = iterate_map_rdd(rdd)\n","        rdd = iterate_reduce_rdd(rdd)\n","        rdd = rdd.distinct()\n","\n","        print(f\"Number of new pairs for iteration #{nb_iteration}:\\t{new_pairs.value}\")\n","        if start_pair == new_pairs.value:\n","            print(\"\\nNo new pair, end of computation\")\n","            break\n","\n","    return rdd"]},{"cell_type":"code","execution_count":8,"id":"07231fbe","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #1:\t8\n","Number of new pairs for iteration #2:\t30\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #3:\t47\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #4:\t51\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #5:\t51\n","\n","No new pair, end of computation\n","Duration in seconds: 21.188074350357056\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 95:==========================================>             (49 + 4) / 64]\r"]},{"name":"stdout","output_type":"stream","text":["Nb of connected components in the graph: 2\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["rdd_raw = load_rdd(dataset_path)\n","rdd = preprocess_rdd(rdd_raw)\n","\n","start_time = time.time()\n","rdd = compute_rdd(rdd)\n","print(f\"Nb of connected components in the graph: {rdd.map(lambda x : x[1]).distinct().count()}\")\n","print(f\"Duration in seconds: {time.time() - start_time}\")"]},{"cell_type":"code","execution_count":null,"id":"ba9634c6","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a160709b","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5557c313","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fe91014d","metadata":{},"outputs":[],"source":["import time\n","import pyspark\n","\n","# This function will perform CCF nb_iteration\n","# It returns the rdd with new pairs calculated by CCF nb_iterations\n","def Calculate_CCF(rdd):\n","    nb_iteration = 0\n","\n","    while True:\n","        nb_iteration += 1\n","        start_nb_pairs = new_pairs.value\n","\n","        rdd_map  = iterate_map_rdd(rdd) # rdd.union(rdd.map(lambda x : (x[1], x[0])))\n","\n","        # CCF-Iterate REDUCE\n","        ccf_iterate_reduce = rdd_map.groupByKey().flatMap(lambda x: countnew_pairs(x)).sortByKey()\n","\n","        # CFF-Dedup MAP & REDUCE\n","        ccf_dedup_map_reduce = ccf_iterate_reduce.distinct()\n","\n","        rdd = ccf_dedup_map_reduce\n","        print(\"It√©ration : \", nb_iteration, \"Number of new_pairs : \", new_pairs.value)\n","        \n","        if start_nb_pairs == new_pairs.value:\n","            break\n","\n","    return rdd"]},{"cell_type":"code","execution_count":null,"id":"35eb9111","metadata":{},"outputs":[],"source":["new_pairs = spark_context.accumulator(0)\n","# dataset = spark_context.textFile(dataset_path, use_unicode=\"False\")\n","# #graph = prepare_dataset(dataset)\n","# graph = rdd\n","\n","rdd_raw = load_rdd(dataset_path)\n","rdd = preprocess_rdd(rdd_raw)\n","\n","\n","t1 = time.time()\n","rdd = Calculate_CCF(rdd)\n","t2 = time.time()\n","print(\"Duration (s) :\", t2 - t1)"]},{"cell_type":"code","execution_count":null,"id":"9e68953c","metadata":{},"outputs":[],"source":["graph.count()"]},{"cell_type":"code","execution_count":null,"id":"56bf55e4","metadata":{},"outputs":[],"source":["graph.map(lambda x : x[1]).distinct().count()"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}