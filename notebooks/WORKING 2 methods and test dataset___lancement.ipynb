{"cells":[{"cell_type":"code","execution_count":null,"id":"a934fbf3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\n","__________ nb of clusters' nodes: 1 - dataset: notre_dame - method: rdd __________\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #1:\t5262811\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #2:\t10558186\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #3:\t14122107\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #4:\t15770386\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #5:\t16068507\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #6:\t16089049\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #7:\t16091331\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #8:\t16091331\n","\n","No new pair, end of computation\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Nb of connected components in the graph: 1\n","Duration in seconds: 196.55817294120789\n","\n","\n","\n","__________ nb of clusters' nodes: 1 - dataset: notre_dame - method: df __________\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #1:\t17965651\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #2:\t19297674\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #3:\t20413623\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #4:\t20679788\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #5:\t20695766\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #6:\t20698048\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #7:\t20698048\n","\n","No new pair, end of computation\n"]},{"name":"stderr","output_type":"stream","text":["22/10/12 19:51:51 WARN org.apache.spark.network.server.TransportChannelHandler: Exception in connection from /10.128.0.5:59756\n","java.io.IOException: Connection reset by peer\n","\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n","\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n","\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n","\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n","\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n","\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n","\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)\n","\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n","\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","22/10/12 19:51:51 ERROR org.apache.spark.network.client.TransportResponseHandler: Still have 1 requests outstanding when connection from /10.128.0.5:59756 is closed\n","22/10/12 19:51:51 WARN org.apache.spark.storage.BlockManagerMasterEndpoint: Error trying to remove broadcast 342 from block manager BlockManagerId(1, dev-m.us-central1-b.c.iasd4-364813.internal, 44399, None)\n","java.io.IOException: Connection reset by peer\n","\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n","\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n","\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n","\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n","\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n","\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n","\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)\n","\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n","\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","22/10/12 19:51:51 ERROR org.apache.spark.network.client.TransportResponseHandler: Still have 1 requests outstanding when connection from /10.128.0.5:59756 is closed\n","22/10/12 19:51:51 WARN org.apache.spark.storage.BlockManagerMasterEndpoint: Error trying to remove broadcast 343 from block manager BlockManagerId(1, dev-m.us-central1-b.c.iasd4-364813.internal, 44399, None)\n","java.io.IOException: Connection from /10.128.0.5:59756 closed\n","\tat org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)\n","\tat org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n","\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n","\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)\n","\tat io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n","\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n","\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)\n","\tat org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n","\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n","\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n","\tat io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)\n","\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","22/10/12 19:51:51 ERROR org.apache.spark.network.client.TransportClient: Failed to send RPC RPC 5521637432122213455 to /10.128.0.5:59756: java.nio.channels.ClosedChannelException\n","java.nio.channels.ClosedChannelException\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865)\n","\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n","\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)\n","\tat io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:767)\n","\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)\n","\tat io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:767)\n","\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n","\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","22/10/12 19:51:51 WARN org.apache.spark.rpc.netty.NettyRpcEnv: Ignored failure: java.io.IOException: Failed to send RPC RPC 5521637432122213455 to /10.128.0.5:59756: java.nio.channels.ClosedChannelException\n","22/10/12 19:51:51 WARN org.apache.spark.storage.BlockManagerMasterEndpoint: No more replicas available for broadcast_343_piece0 !\n","22/10/12 19:51:51 WARN org.apache.spark.storage.BlockManagerMasterEndpoint: No more replicas available for broadcast_342_piece0 !\n","22/10/12 19:51:51 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1665599597103_0001_01_000001 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:51:51.845]Container killed on request. Exit code is 137\n","[2022-10-12 19:51:51.846]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:51:51.846]Killed by external signal\n",".\n","22/10/12 19:51:51 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1665599597103_0001_01_000001 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:51:51.845]Container killed on request. Exit code is 137\n","[2022-10-12 19:51:51.846]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:51:51.846]Killed by external signal\n",".\n","22/10/12 19:51:51 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 1 on dev-m.us-central1-b.c.iasd4-364813.internal: Container from a bad node: container_1665599597103_0001_01_000001 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:51:51.845]Container killed on request. Exit code is 137\n","[2022-10-12 19:51:51.846]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:51:51.846]Killed by external signal\n",".\n","22/10/12 19:51:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 1368.0 (TID 8246) (dev-m.us-central1-b.c.iasd4-364813.internal executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000001 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:51:51.845]Container killed on request. Exit code is 137\n","[2022-10-12 19:51:51.846]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:51:51.846]Killed by external signal\n",".\n","22/10/12 19:51:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 1368.0 (TID 8245) (dev-m.us-central1-b.c.iasd4-364813.internal executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000001 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:51:51.845]Container killed on request. Exit code is 137\n","[2022-10-12 19:51:51.846]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:51:51.846]Killed by external signal\n",".\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Nb of connected components in the graph: 1\n","Duration in seconds: 145.22082543373108\n","\n","\n","\n","__________ nb of clusters' nodes: 1 - dataset: berk_stan - method: rdd __________\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #1:\t48973360\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #2:\t71406862\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #3:\t81062615\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #4:\t86413160\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #5:\t88622651\n"]},{"name":"stderr","output_type":"stream","text":["22/10/12 19:55:41 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1665599597103_0001_01_000003 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:55:41.081]Container killed on request. Exit code is 137\n","[2022-10-12 19:55:41.081]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:55:41.081]Killed by external signal\n",".\n","22/10/12 19:55:41 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1665599597103_0001_01_000003 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:55:41.081]Container killed on request. Exit code is 137\n","[2022-10-12 19:55:41.081]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:55:41.081]Killed by external signal\n",".\n","22/10/12 19:55:41 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 3 on dev-m.us-central1-b.c.iasd4-364813.internal: Container from a bad node: container_1665599597103_0001_01_000003 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:55:41.081]Container killed on request. Exit code is 137\n","[2022-10-12 19:55:41.081]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:55:41.081]Killed by external signal\n",".\n","22/10/12 19:55:41 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 81.0 in stage 1526.0 (TID 8962) (dev-m.us-central1-b.c.iasd4-364813.internal executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000003 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:55:41.081]Container killed on request. Exit code is 137\n","[2022-10-12 19:55:41.081]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:55:41.081]Killed by external signal\n",".\n","22/10/12 19:55:41 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 80.0 in stage 1526.0 (TID 8961) (dev-m.us-central1-b.c.iasd4-364813.internal executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000003 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:55:41.081]Container killed on request. Exit code is 137\n","[2022-10-12 19:55:41.081]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:55:41.081]Killed by external signal\n",".\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #6:\t89477279\n"]},{"name":"stderr","output_type":"stream","text":["22/10/12 19:56:30 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1665599597103_0001_01_000004 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:56:30.609]Container killed on request. Exit code is 137\n","[2022-10-12 19:56:30.609]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:56:30.610]Killed by external signal\n",".\n","22/10/12 19:56:30 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1665599597103_0001_01_000004 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:56:30.609]Container killed on request. Exit code is 137\n","[2022-10-12 19:56:30.609]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:56:30.610]Killed by external signal\n",".\n","22/10/12 19:56:30 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 4 on dev-m.us-central1-b.c.iasd4-364813.internal: Container from a bad node: container_1665599597103_0001_01_000004 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:56:30.609]Container killed on request. Exit code is 137\n","[2022-10-12 19:56:30.609]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:56:30.610]Killed by external signal\n",".\n","22/10/12 19:56:30 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 48.0 in stage 1563.0 (TID 9571) (dev-m.us-central1-b.c.iasd4-364813.internal executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000004 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:56:30.609]Container killed on request. Exit code is 137\n","[2022-10-12 19:56:30.609]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:56:30.610]Killed by external signal\n",".\n","22/10/12 19:56:30 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 47.0 in stage 1563.0 (TID 9570) (dev-m.us-central1-b.c.iasd4-364813.internal executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000004 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 19:56:30.609]Container killed on request. Exit code is 137\n","[2022-10-12 19:56:30.609]Container exited with a non-zero exit code 137. \n","[2022-10-12 19:56:30.610]Killed by external signal\n",".\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #7:\t90077873\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #9:\t91359959\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #10:\t91872269\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #11:\t92051146\n"]},{"name":"stderr","output_type":"stream","text":["22/10/12 20:08:27 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1665599597103_0001_01_000005 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:08:26.897]Container killed on request. Exit code is 137\n","[2022-10-12 20:08:26.897]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:08:26.898]Killed by external signal\n",".\n","22/10/12 20:08:27 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 5 for reason Container from a bad node: container_1665599597103_0001_01_000005 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:08:26.897]Container killed on request. Exit code is 137\n","[2022-10-12 20:08:26.897]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:08:26.898]Killed by external signal\n",".\n","22/10/12 20:08:27 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 5 on dev-m.us-central1-b.c.iasd4-364813.internal: Container from a bad node: container_1665599597103_0001_01_000005 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:08:26.897]Container killed on request. Exit code is 137\n","[2022-10-12 20:08:26.897]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:08:26.898]Killed by external signal\n",".\n","22/10/12 20:08:27 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1219.0 in stage 1836.0 (TID 42232) (dev-m.us-central1-b.c.iasd4-364813.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000005 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:08:26.897]Container killed on request. Exit code is 137\n","[2022-10-12 20:08:26.897]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:08:26.898]Killed by external signal\n",".\n","22/10/12 20:08:27 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1218.0 in stage 1836.0 (TID 42231) (dev-m.us-central1-b.c.iasd4-364813.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000005 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:08:26.897]Container killed on request. Exit code is 137\n","[2022-10-12 20:08:26.897]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:08:26.898]Killed by external signal\n",".\n","22/10/12 20:09:33 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1665599597103_0001_01_000006 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:09:33.285]Container killed on request. Exit code is 137\n","[2022-10-12 20:09:33.285]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:09:33.286]Killed by external signal\n",".\n","22/10/12 20:09:33 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 6 for reason Container from a bad node: container_1665599597103_0001_01_000006 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:09:33.285]Container killed on request. Exit code is 137\n","[2022-10-12 20:09:33.285]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:09:33.286]Killed by external signal\n",".\n","22/10/12 20:09:33 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 6 on dev-m.us-central1-b.c.iasd4-364813.internal: Container from a bad node: container_1665599597103_0001_01_000006 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:09:33.285]Container killed on request. Exit code is 137\n","[2022-10-12 20:09:33.285]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:09:33.286]Killed by external signal\n",".\n","22/10/12 20:09:33 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3475.0 in stage 1836.0 (TID 44490) (dev-m.us-central1-b.c.iasd4-364813.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000006 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:09:33.285]Container killed on request. Exit code is 137\n","[2022-10-12 20:09:33.285]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:09:33.286]Killed by external signal\n",".\n","22/10/12 20:09:33 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3476.0 in stage 1836.0 (TID 44491) (dev-m.us-central1-b.c.iasd4-364813.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000006 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:09:33.285]Container killed on request. Exit code is 137\n","[2022-10-12 20:09:33.285]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:09:33.286]Killed by external signal\n",".\n","22/10/12 20:10:08 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1665599597103_0001_01_000007 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:10:08.526]Container killed on request. Exit code is 137\n","[2022-10-12 20:10:08.526]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:10:08.527]Killed by external signal\n",".\n","22/10/12 20:10:08 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 7 on dev-m.us-central1-b.c.iasd4-364813.internal: Container from a bad node: container_1665599597103_0001_01_000007 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:10:08.526]Container killed on request. Exit code is 137\n","[2022-10-12 20:10:08.526]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:10:08.527]Killed by external signal\n",".\n","22/10/12 20:10:08 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 377.0 in stage 1837.0 (TID 45490) (dev-m.us-central1-b.c.iasd4-364813.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000007 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:10:08.526]Container killed on request. Exit code is 137\n","[2022-10-12 20:10:08.526]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:10:08.527]Killed by external signal\n",".\n","22/10/12 20:10:08 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 378.0 in stage 1837.0 (TID 45491) (dev-m.us-central1-b.c.iasd4-364813.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000007 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:10:08.526]Container killed on request. Exit code is 137\n","[2022-10-12 20:10:08.526]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:10:08.527]Killed by external signal\n",".\n","22/10/12 20:10:08 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 7 for reason Container from a bad node: container_1665599597103_0001_01_000007 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:10:08.526]Container killed on request. Exit code is 137\n","[2022-10-12 20:10:08.526]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:10:08.527]Killed by external signal\n",".\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #12:\t92065666\n"]},{"name":"stderr","output_type":"stream","text":["22/10/12 20:22:13 WARN org.apache.spark.network.server.TransportChannelHandler: Exception in connection from /10.128.0.5:41540\n","java.io.IOException: Connection reset by peer\n","\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n","\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n","\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n","\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n","\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n","\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n","\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)\n","\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n","\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","22/10/12 20:22:14 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1665599597103_0001_01_000008 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:22:14.051]Container killed on request. Exit code is 137\n","[2022-10-12 20:22:14.052]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:22:14.052]Killed by external signal\n",".\n","22/10/12 20:22:14 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 8 on dev-m.us-central1-b.c.iasd4-364813.internal: Container from a bad node: container_1665599597103_0001_01_000008 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:22:14.051]Container killed on request. Exit code is 137\n","[2022-10-12 20:22:14.052]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:22:14.052]Killed by external signal\n",".\n","22/10/12 20:22:14 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 8 for reason Container from a bad node: container_1665599597103_0001_01_000008 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:22:14.051]Container killed on request. Exit code is 137\n","[2022-10-12 20:22:14.052]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:22:14.052]Killed by external signal\n",".\n","22/10/12 20:22:14 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 5070.0 in stage 1910.0 (TID 87049) (dev-m.us-central1-b.c.iasd4-364813.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000008 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:22:14.051]Container killed on request. Exit code is 137\n","[2022-10-12 20:22:14.052]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:22:14.052]Killed by external signal\n",".\n","22/10/12 20:22:14 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 5069.0 in stage 1910.0 (TID 87048) (dev-m.us-central1-b.c.iasd4-364813.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_1665599597103_0001_01_000008 on host: dev-m.us-central1-b.c.iasd4-364813.internal. Exit status: 137. Diagnostics: [2022-10-12 20:22:14.051]Container killed on request. Exit code is 137\n","[2022-10-12 20:22:14.052]Container exited with a non-zero exit code 137. \n","[2022-10-12 20:22:14.052]Killed by external signal\n",".\n","[Stage 1910:=====================================>            (6202 + 2) / 8192]\n","KeyboardInterrupt\n","\n","[Stage 1910:=====================================>            (6212 + 2) / 8192]\r"]}],"source":["import time\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import IntegerType, BooleanType, DateType, StructType, StructField\n","from pyspark.sql.functions import explode, col, split, array, array_min, concat, least, collect_set, size, sum, min\n","\n","\n","BUCKET_INPUT_PATH = \"gs://iasd-input-data\"\n","NB_WORKER_NODES = 1  # -------------- to be changed at each run\n","\n","\n","spark_session = SparkSession \\\n","    .builder \\\n","    .appName(\"PySpark App by Olivier & Jean-Loulou\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()\n","spark_context = spark_session.sparkContext\n","\n","\n","def load_rdd(path):\n","    return spark_context.textFile(path)\n","\n","\n","def load_df(path):\n","    return spark_session.read.format(\"csv\").option(\"header\",\"false\")\\\n","                .load(path)\n","\n","\n","def preprocess_rdd(rdd):\n","    return rdd.filter(lambda x: \"#\" not in x) \\\n","                .map(lambda x: x.split(\"\\t\")) \\\n","                .map(lambda x: (int(x[0]), int(x[1])))\n","\n","\n","def preprocess_df(df):\n","    col_name = df.columns[0]\n","    return df.filter(f\"{col_name} NOT LIKE '#%'\")\\\n","                .withColumn('k', split(df[col_name], '\\t').getItem(0)) \\\n","                .withColumn('v', split(df[col_name], '\\t').getItem(1)) \\\n","                .drop(col_name)\\\n","                .withColumn(\"k\",col(\"k\").cast(IntegerType())) \\\n","                .withColumn(\"v\",col(\"v\").cast(IntegerType()))\n","\n","\n","def iterate_map_rdd(rdd):\n","    return rdd.union(rdd.map(lambda x : (x[1], x[0])))\n","\n","\n","def iterate_map_df(df):\n","    return df.union(df.select(col(\"v\").alias(\"k\"), col(\"k\").alias(\"v\")))\n","\n","\n","# countnb_new_pair function to know if additional CCF iteration is needed\n","def count_nb_new_pair(x):\n","  global nb_new_pair\n","  k, values = x\n","  min, value_list = k, []\n","  for v in values:\n","    if v < min:\n","       min = v\n","    value_list.append(v)\n","  if min < k:\n","    yield((k, min))\n","    for v in value_list:\n","      if min != v:\n","        nb_new_pair += 1\n","        yield((v, min))\n","        \n","\n","def iterate_reduce_rdd(rdd):\n","    return rdd.groupByKey().flatMap(lambda x: count_nb_new_pair(x)).sortByKey()\n","\n","\n","def iterate_reduce_df(df):\n","    global nb_new_pair\n","\n","    df = df.groupBy(col(\"k\")).agg(collect_set(\"v\").alias(\"v\"))\\\n","                                            .withColumn(\"min\", least(col(\"k\"), array_min(\"v\")))\\\n","                                            .filter((col(\"k\")!=col('min')))\n","\n","    nb_new_pair += df.withColumn(\"count\", size(\"v\")-1).select(sum(\"count\")).collect()[0][0]\n","\n","    return df.select(col(\"min\").alias(\"a_min\"), concat(array(col(\"k\")), col(\"v\")).alias(\"valueList\"))\\\n","                                                    .withColumn(\"valueList\", explode(\"valueList\"))\\\n","                                                    .filter((col('a_min')!=col('valueList')))\\\n","                                                    .select(col('a_min').alias(\"k\"), col('valueList').alias(\"v\"))\n","\n","\n","def compute_rdd(rdd):\n","    nb_iteration = 0\n","    while True:\n","        nb_iteration += 1\n","        start_pair = nb_new_pair.value\n","\n","        rdd = iterate_map_rdd(rdd)\n","        rdd = iterate_reduce_rdd(rdd)\n","        rdd = rdd.distinct()\n","\n","        print(f\"Number of new pairs for iteration #{nb_iteration}:\\t{nb_new_pair.value}\")\n","        if start_pair == nb_new_pair.value:\n","            print(\"\\nNo new pair, end of computation\")\n","            break\n","    return rdd\n","\n","\n","def compute_cc_df(df):\n","    nb_iteration = 0\n","    while True:\n","        nb_iteration += 1\n","        nb_pairs_start = nb_new_pair.value\n","\n","        df = iterate_map_df(df)\n","        df = iterate_reduce_df(df)\n","        df = df.distinct()\n","        \n","        print(f\"Number of new pairs for iteration #{nb_iteration}:\\t{nb_new_pair.value}\")\n","        if nb_pairs_start == nb_new_pair.value:\n","            print(\"\\nNo new pair, end of computation\")\n","            break\n","    return df\n","\n","\n","def workflow_rdd(path):\n","    rdd_raw = load_rdd(path)\n","    rdd = preprocess_rdd(rdd_raw)\n","    start_time = time.time()\n","    rdd = compute_rdd(rdd)\n","    print(f\"Nb of connected components in the graph: {rdd.map(lambda x : x[1]).distinct().count()}\")\n","    print(f\"Duration in seconds: {time.time() - start_time}\")\n","\n","\n","def workflow_df(path):\n","    df_raw = load_df(path)\n","    df = preprocess_df(df_raw)\n","    start_time = time.time()\n","    df = compute_cc_df(df)\n","    print(f\"Nb of connected components in the graph: {df.select('k').distinct().count()}\")\n","    print(f\"Duration in seconds: {time.time() - start_time}\")   \n","    \n","\n","def main():\n","    \n","    dataset_paths = {\n","        \"notre_dame\": f\"{BUCKET_INPUT_PATH}/web-NotreDame.txt\",\n","        \"berk_stan\": f\"{BUCKET_INPUT_PATH}/web-BerkStan.txt\",\n","        \"stanford\": f\"{BUCKET_INPUT_PATH}/web-Stanford.txt\",\n","        \"google\": f\"{BUCKET_INPUT_PATH}/web-Google.txt\"\n","    }\n","    computation_methods = {\n","        \"rdd\": workflow_rdd,\n","        \"df\": workflow_df\n","    }\n","    \n","    for dataset in dataset_paths.keys():\n","        for method in computation_methods.keys():\n","            print(\"\\n\"* 3 + \"_\" * 10 + \n","                  f\" nb of clusters' nodes: {NB_WORKER_NODES} - dataset: {dataset} - method: {method} \"\n","                  + \"_\" * 10)\n","            nb_new_pair = sc.accumulator(0)\n","            computation_methods[method](dataset_paths[dataset])\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"id":"c962379d","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}