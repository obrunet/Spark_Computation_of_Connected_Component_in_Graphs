{"cells":[{"cell_type":"code","execution_count":1,"id":"a934fbf3","metadata":{},"outputs":[],"source":["import time\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import IntegerType, BooleanType, DateType, StructType, StructField\n","from pyspark.sql.functions import explode, col, split, array, array_min, concat, least, collect_set, size, sum, min\n","\n","\n","BUCKET_INPUT_PATH = \"gs://iasd-input-data\"\n","DATASET_PATHS = {\n","    \"notre_dame\": f\"{BUCKET_INPUT_PATH}/web-NotreDame.txt\",\n","    \"berk_stan.txt\": f\"{BUCKET_INPUT_PATH}/web-BerkStan.txt\",\n","    \"stanford.txt\": f\"{BUCKET_INPUT_PATH}/web-Stanford.txt\",\n","    \"google.txt\": f\"{BUCKET_INPUT_PATH}/web-Google.txt\"\n","}\n","\n","dataset_path = f\"{BUCKET_INPUT_PATH}/test.txt\"\n","\n"]},{"cell_type":"code","execution_count":2,"id":"ac7e6659","metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://dev-m.us-central1-a.c.iasd4-364813.internal:39269\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7ff79b59cf40>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["spark_session = SparkSession \\\n","    .builder \\\n","    .appName(\"Python Spark SQL basic example\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()\n","\n","spark_context = spark_session.sparkContext\n","\n","spark_session"]},{"cell_type":"code","execution_count":3,"id":"37179245","metadata":{},"outputs":[],"source":["def load_df(path):\n","    return spark_session.read.format(\"csv\").option(\"header\",\"false\")\\\n","                .load(path)\n","\n","\n","def preprocess_df(df):\n","    col_name = df.columns[0]\n","    return df.filter(f\"{col_name} NOT LIKE '#%'\")\\\n","                .withColumn('k', split(df[col_name], '\\t').getItem(0)) \\\n","                .withColumn('v', split(df[col_name], '\\t').getItem(1)) \\\n","                .drop(col_name)\\\n","                .withColumn(\"k\",col(\"k\").cast(IntegerType())) \\\n","                .withColumn(\"v\",col(\"v\").cast(IntegerType()))"]},{"cell_type":"code","execution_count":null,"id":"1f09dbf7","metadata":{},"outputs":[],"source":["df_raw = load_df(dataset_path)\n","df_raw.show(6)"]},{"cell_type":"code","execution_count":null,"id":"dbfe2449","metadata":{},"outputs":[],"source":["df = preprocess_df(df_raw)\n","df.show(5)"]},{"cell_type":"code","execution_count":4,"id":"a2ace4c6","metadata":{},"outputs":[],"source":["def iterate_map_df(df):\n","    return df.union(df.select(col(\"v\").alias(\"k\"), col(\"k\").alias(\"v\")))"]},{"cell_type":"code","execution_count":5,"id":"26b00c01","metadata":{},"outputs":[],"source":["def iterate_reduce_df(df):\n","    global nb_new_pair\n","\n","    df = df.groupBy(col(\"k\")).agg(collect_set(\"v\").alias(\"v\"))\\\n","                                            .withColumn(\"min\", least(col(\"k\"), array_min(\"v\")))\\\n","                                            .filter((col(\"k\")!=col('min')))\n","\n","    nb_new_pair += df.withColumn(\"count\", size(\"v\")-1).select(sum(\"count\")).collect()[0][0]\n","\n","    return df.select(col(\"min\").alias(\"a_min\"), concat(array(col(\"k\")), col(\"v\")).alias(\"valueList\"))\\\n","                                                    .withColumn(\"valueList\", explode(\"valueList\"))\\\n","                                                    .filter((col('a_min')!=col('valueList')))\\\n","                                                    .select(col('a_min').alias(\"k\"), col('valueList').alias(\"v\"))"]},{"cell_type":"code","execution_count":6,"id":"8f032e1f","metadata":{},"outputs":[],"source":["from pyspark.sql.functions import explode, col, split, array, array_min, concat, least, collect_set, size, sum\n","\n","nb_new_pair = sc.accumulator(0)  \n","\n","\n","def compute_cc_df(df):\n","    nb_iteration = 0\n","    while True:\n","        nb_iteration += 1\n","        nb_pairs_start = nb_new_pair.value\n","\n","        df = iterate_map_df(df)\n","        df = iterate_reduce_df(df)\n","        df = df.distinct()\n","        \n","        print(f\"Number of new pairs for iteration #{nb_iteration}:\\t{nb_new_pair.value}\")\n","        if nb_pairs_start == nb_new_pair.value:\n","            print(\"\\nNo new pair, end of computation\")\n","            break\n","\n","    return df"]},{"cell_type":"code","execution_count":7,"id":"912e5d1c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #1:\t4\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Number of new pairs for iteration #2:\t13\n","Number of new pairs for iteration #3:\t17\n","Number of new pairs for iteration #4:\t17\n","\n","No new pair, end of computation\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 130:>                                                        (0 + 4) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["Nb of connected components in the graph: 2\n","Duration in seconds: 25.979886770248413\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_raw = load_df(dataset_path)\n","df = preprocess_df(df_raw)\n","\n","start_time = time.time()\n","df = compute_cc_df(df)\n","print(f\"Nb of connected components in the graph: {df.select('k').distinct().count()}\")\n","print(f\"Duration in seconds: {time.time() - start_time}\")"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}