{"cells":[{"cell_type":"code","source":["\"\"\"\n# Title : PySpark Script to compute connected components of graph\n# Description : \n# Author : O. Brunet & J.L. Lezaun\n# Date : Oct. 22\n# Version : final\n\"\"\"\n\nimport time\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import IntegerType\n\n\n# create a spark session and retrieve the spark context from it\nspark_session = SparkSession \\\n    .builder \\\n    .appName(\"PySpark App by Olivier & Jean-Loulou\") \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()\nspark_context = spark_session.sparkContext\n\n# initialize nb_new_pair as a spark accumulator\nnb_new_pair = spark_context.accumulator(0)\n\n\ndef load_rdd(path):\n    \"\"\"Recieve the path of file to load and return an RDD of the dataset\"\"\"\n    return spark_context.textFile(path)\n\n\ndef load_df(path):\n    \"\"\"Recieve the path of file to load and return a DF of the dataset\"\"\"\n    return spark_session.read.format(\"csv\").option(\"header\",\"false\")\\\n                .load(path)\n\n\ndef preprocess_rdd(rdd):\n    \"\"\"Recieve an RDD with the raw data and return a new RDD without multilines headers\n    starting with '#', and columns splitted according to the tab separator\"\"\"\n    return rdd.filter(lambda x: \"#\" not in x) \\\n                .map(lambda x: x.split(\"\\t\")) \\\n                .map(lambda x: (int(x[0]), int(x[1])))\n\n\ndef preprocess_df(df):\n    \"\"\"Recieve a DF with the raw data and return a new DF without multilines headers\n    starting with '#', and columns splitted according to the tab separator\"\"\"\n    col_name = df.columns[0]\n    return df.filter(f\"{col_name} NOT LIKE '#%'\")\\\n                .withColumn('k', split(df[col_name], '\\t').getItem(0)) \\\n                .withColumn('v', split(df[col_name], '\\t').getItem(1)) \\\n                .drop(col_name)\\\n                .withColumn(\"k\",col(\"k\").cast(IntegerType())) \\\n                .withColumn(\"v\",col(\"v\").cast(IntegerType()))\n\n\ndef iterate_map_rdd(rdd):\n    \"\"\"Recieve an RDD with (k, v) and return a new RDD resulting of the concatenation of the \n    original input RDD and itself where keys & values were inverted (v, k)\"\"\"\n    return rdd.union(rdd.map(lambda x : (x[1], x[0])))\n\n\ndef iterate_map_df(df):\n    \"\"\"Recieve a DF with 2 columns 'k', 'v' and return a new DF resulting of the concatenation \n    of the original input DF and itself where columns were inverted 'k', 'v'\"\"\"\n    return df.union(df.select(col(\"v\").alias(\"k\"), col(\"k\").alias(\"v\")))\n\n\ndef count_nb_new_pair(x):\n    \"\"\"Count the number of new pairs - function used in iterate_reduce_rdd in order to \n    determine if new edges were attached in a component and if the process is over or not\"\"\"\n    global nb_new_pair\n    k, values = x\n    min, value_list = k, []\n    for v in values:\n        if v < min:\n            min = v\n        value_list.append(v)\n    if min < k:\n        yield((k, min))\n        for v in value_list:\n            if min != v:\n                nb_new_pair += 1\n                yield((v, min))\n        \n\ndef iterate_reduce_rdd(rdd):\n    \"\"\"Recieve an RDD alreday processed by iterate_map_rdd(), and for each component\n    count new pairs with count_nb_new_pair(), the return RDD is sorted by keys\"\"\"\n    return rdd.groupByKey().flatMap(lambda x: count_nb_new_pair(x)).sortByKey()\n\n\ndef iterate_reduce_df(df):\n    \"\"\"Recieve a DF alreday processed by iterate_map_df(), and for each component\n    count new pairs, the return DF transformed\"\"\"    \n    global nb_new_pair\n    df = df.groupBy(col(\"k\")).agg(collect_set(\"v\").alias(\"v\"))\\\n                                            .withColumn(\"min\", least(col(\"k\"), array_min(\"v\")))\\\n                                            .filter((col(\"k\")!=col('min')))\n\n    nb_new_pair += df.withColumn(\"count\", size(\"v\")-1).select(sum(\"count\")).collect()[0][0]\n\n    return df.select(col(\"min\").alias(\"a_min\"), concat(array(col(\"k\")), col(\"v\")).alias(\"valueList\"))\\\n                                                    .withColumn(\"valueList\", explode(\"valueList\"))\\\n                                                    .filter((col('a_min')!=col('valueList')))\\\n                                                    .select(col('a_min').alias(\"k\"), col('valueList').alias(\"v\"))\n\n\ndef compute_cc_rdd(rdd):\n    \"\"\"Recieve a preprocessed RDD and compute CCF according to several iterations jobs of iterate_map/reduce_rdd, dedup.\n    When no new pair were counted: return an RDD with the componentIDs of each group of connected edges\"\"\"\n    nb_iteration = 0\n    while True:\n        nb_iteration += 1\n        start_pair = nb_new_pair.value\n\n        rdd = iterate_map_rdd(rdd)\n        rdd = iterate_reduce_rdd(rdd)\n        rdd = rdd.distinct()  # used for iterate_dedup / deduplication\n\n        print(f\"Number of new pairs for iteration #{nb_iteration}:\\t{nb_new_pair.value}\")\n        if start_pair == nb_new_pair.value:\n            print(\"\\nNo new pair, end of computation\")\n            break\n    return rdd\n\n\ndef compute_cc_df(df):\n    \"\"\"Recieve a preprocessed DF and compute CCF according to several iterations jobs of iterate_map/reduce_df, dedup.\n    When no new pair were counted: return a DF with the componentIDs of each group of connected edges\"\"\"\n    nb_iteration = 0\n    while True:\n        nb_iteration += 1\n        nb_pairs_start = nb_new_pair.value\n\n        df = iterate_map_df(df)\n        df = iterate_reduce_df(df)\n        df = df.distinct()\n        \n        print(f\"Number of new pairs for iteration #{nb_iteration}:\\t{nb_new_pair.value}\")\n        if nb_pairs_start == nb_new_pair.value:\n            print(\"\\nNo new pair, end of computation\")\n            break\n    return df\n\n\ndef workflow_rdd(path):\n    \"\"\"Recieve the dataset path, and realize all the transformations / computation in RDD: loading,\n    preprocessing, CCF computation, calculate time and the number of distinct connected components\"\"\"\n    rdd_raw = load_rdd(path)\n    rdd = preprocess_rdd(rdd_raw)\n    start_time = time.time()\n    rdd = compute_cc_rdd(rdd)\n    print(f\"Nb of connected components in the graph: {rdd.map(lambda x : x[1]).distinct().count()}\")\n    print(f\"Duration in seconds: {time.time() - start_time}\")\n\n\ndef workflow_df(path):\n    \"\"\"Recieve the dataset path, and realize all the transformations / computation in DF: loading,\n    preprocessing, CCF computation, calculate time and the number of distinct connected components\"\"\"\n    df_raw = load_df(path)\n    df = preprocess_df(df_raw)\n    start_time = time.time()\n    df = compute_cc_df(df)\n    print(f\"Nb of connected components in the graph: {df.select('k').distinct().count()}\")\n    print(f\"Duration in seconds: {time.time() - start_time}\")   \n    \n\ndef main():\n    \n    dataset_paths = {\n#          \"notre_dame\": \"/FileStore/tables/web_NotreDame.txt\"\n#          \"berk_stan\": \"/FileStore/tables/web_BerkStan.txt\"\n#          \"stanford\": \"/FileStore/tables/web_Stanford.txt\",\n         \"google\": \"/FileStore/tables/web_Google-2.txt\"\n    }\n    \n    computation_methods = {\n        \"rdd\": workflow_rdd,\n        \"df\": workflow_df\n    }\n    \n    # loop on all the datasets & methods (RDD or DF) using previsous dictionnaries\n    for dataset in dataset_paths.keys():\n        for method in computation_methods.keys():\n            print(\"\\n\"* 3 + \"_\" * 10 + \n                  f\" dataset: {dataset} - method: {method} \"\n                  + \"_\" * 10)\n            computation_methods[method](dataset_paths[dataset])\n\n\nif __name__ == \"__main__\":\n    main()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c11666d-d518-48a5-bc87-10882bda91e4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n\n\n__________ dataset: google - method: rdd __________\nNumber of new pairs for iteration #1:\t17104464\nNumber of new pairs for iteration #2:\t35173598\nNumber of new pairs for iteration #3:\t46489593\nNumber of new pairs for iteration #4:\t57545273\nNumber of new pairs for iteration #5:\t65244373\nNumber of new pairs for iteration #6:\t67323262\nNumber of new pairs for iteration #7:\t67412681\nNumber of new pairs for iteration #8:\t67413999\nNumber of new pairs for iteration #9:\t67413999\n\nNo new pair, end of computation\nNb of connected components in the graph: 2746\nDuration in seconds: 1012.0471704006195\n\n\n\n__________ dataset: google - method: df __________\nNumber of new pairs for iteration #1:\t74637779\nNumber of new pairs for iteration #2:\t79396230\nNumber of new pairs for iteration #3:\t82675002\nNumber of new pairs for iteration #4:\t86563456\nNumber of new pairs for iteration #5:\t88468779\nNumber of new pairs for iteration #6:\t88555562\nNumber of new pairs for iteration #7:\t88556880\nNumber of new pairs for iteration #8:\t88556880\n\nNo new pair, end of computation\nNb of connected components in the graph: 2746\nDuration in seconds: 1165.4793045520782\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\n\n\n__________ dataset: google - method: rdd __________\nNumber of new pairs for iteration #1:\t17104464\nNumber of new pairs for iteration #2:\t35173598\nNumber of new pairs for iteration #3:\t46489593\nNumber of new pairs for iteration #4:\t57545273\nNumber of new pairs for iteration #5:\t65244373\nNumber of new pairs for iteration #6:\t67323262\nNumber of new pairs for iteration #7:\t67412681\nNumber of new pairs for iteration #8:\t67413999\nNumber of new pairs for iteration #9:\t67413999\n\nNo new pair, end of computation\nNb of connected components in the graph: 2746\nDuration in seconds: 1012.0471704006195\n\n\n\n__________ dataset: google - method: df __________\nNumber of new pairs for iteration #1:\t74637779\nNumber of new pairs for iteration #2:\t79396230\nNumber of new pairs for iteration #3:\t82675002\nNumber of new pairs for iteration #4:\t86563456\nNumber of new pairs for iteration #5:\t88468779\nNumber of new pairs for iteration #6:\t88555562\nNumber of new pairs for iteration #7:\t88556880\nNumber of new pairs for iteration #8:\t88556880\n\nNo new pair, end of computation\nNb of connected components in the graph: 2746\nDuration in seconds: 1165.4793045520782\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a94694d-4adf-410e-bc68-a2a09a325d7c"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ccf_databricks","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1276098126639203}},"nbformat":4,"nbformat_minor":0}
